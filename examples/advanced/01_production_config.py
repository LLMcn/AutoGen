#!/usr/bin/env python3
"""
AutoGen å­¦ä¹ é¡¹ç›® - é«˜çº§ç¤ºä¾‹1: ç”Ÿäº§çº§é…ç½®ç®¡ç†

å±•ç¤ºä¼ä¸šçº§AutoGenç³»ç»Ÿçš„é…ç½®ç®¡ç†æœ€ä½³å®è·µã€‚

å­¦ä¹ è¦ç‚¹:
- ç¯å¢ƒé…ç½®ç®¡ç†
- å®‰å…¨çš„APIå¯†é’¥ç®¡ç†
- æ¨¡å‹é…ç½®å’Œåˆ‡æ¢
- æ—¥å¿—é…ç½®
- æ€§èƒ½ç›‘æ§é…ç½®
- é”™è¯¯å¤„ç†é…ç½®
"""

import asyncio
import json
import logging
import os
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.conditions import MaxMessageTermination
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_core.models import ModelInfo
from autogen_core.tools import FunctionTool
from autogen_ext.models.openai import OpenAIChatCompletionClient
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class Environment(Enum):
    """ç¯å¢ƒç±»å‹æšä¸¾"""

    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«æšä¸¾"""

    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""

    name: str
    provider: str
    api_key_env: str
    base_url: str | None = None
    temperature: float = 0.7
    max_tokens: int = 4000
    timeout: int = 30
    retry_count: int = 3


class ConfigurationError(Exception):
    """é…ç½®é”™è¯¯å¼‚å¸¸"""


@dataclass
class ProductionConfig:
    """ç”Ÿäº§çº§é…ç½®ç®¡ç†ç±»"""

    # ç¯å¢ƒé…ç½®
    environment: Environment = Environment.DEVELOPMENT
    debug: bool = True

    # APIé…ç½®
    api_configs: dict[str, ModelConfig] = field(default_factory=dict)
    default_model: str = "deepseek"

    # æ—¥å¿—é…ç½®
    log_level: LogLevel = LogLevel.INFO
    log_file: str | None = None
    log_format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

    # æ€§èƒ½é…ç½®
    max_concurrent_requests: int = 10
    request_timeout: int = 30
    cache_enabled: bool = True
    cache_ttl: int = 3600

    # å®‰å…¨é…ç½®
    enable_rate_limiting: bool = True
    max_requests_per_minute: int = 60
    enable_audit_logging: bool = True

    # ç›‘æ§é…ç½®
    enable_metrics: bool = True
    metrics_port: int = 8080
    health_check_interval: int = 30

    def __post_init__(self):
        """åˆå§‹åŒ–åçš„é…ç½®éªŒè¯å’Œè®¾ç½®"""
        self._setup_logging()
        self._load_model_configs()
        self._validate_config()

    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        logging.basicConfig(
            level=getattr(logging, self.log_level.value),
            format=self.log_format,
            filename=self.log_file,
        )

        # ä¸ºç”Ÿäº§ç¯å¢ƒæ·»åŠ é¢å¤–çš„æ—¥å¿—å¤„ç†å™¨
        if self.environment == Environment.PRODUCTION:
            # æ·»åŠ æ–‡ä»¶è½®è½¬å¤„ç†å™¨
            from logging.handlers import RotatingFileHandler

            handler = RotatingFileHandler(
                self.log_file or "autogen_production.log",
                maxBytes=10 * 1024 * 1024,  # 10MB
                backupCount=5,
            )
            handler.setFormatter(logging.Formatter(self.log_format))
            logging.getLogger().addHandler(handler)

    def _load_model_configs(self) -> None:
        """åŠ è½½æ¨¡å‹é…ç½®"""
        # DeepSeeké…ç½®
        self.api_configs["deepseek"] = ModelConfig(
            name="deepseek-chat",
            provider="deepseek",
            api_key_env="OPENAI_API_KEY",
            base_url="https://api.deepseek.com/v1",
            temperature=0.7,
            max_tokens=4000,
        )

        # OpenAIé…ç½®ï¼ˆå¤‡ç”¨ï¼‰
        self.api_configs["openai"] = ModelConfig(
            name="gpt-4",
            provider="openai",
            api_key_env="OPENAI_API_KEY_BACKUP",
            base_url="https://api.openai.com/v1",
            temperature=0.7,
            max_tokens=4000,
        )

        # æœ¬åœ°æ¨¡å‹é…ç½®ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        if self.environment == Environment.DEVELOPMENT:
            self.api_configs["local"] = ModelConfig(
                name="llama2",
                provider="local",
                api_key_env="LOCAL_API_KEY",
                base_url="http://localhost:8000/v1",
                temperature=0.8,
                max_tokens=2000,
            )

    def _validate_config(self) -> None:
        """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
        # éªŒè¯é»˜è®¤æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if self.default_model not in self.api_configs:
            raise ConfigurationError(f"é»˜è®¤æ¨¡å‹ '{self.default_model}' æœªåœ¨é…ç½®ä¸­æ‰¾åˆ°")

        # éªŒè¯APIå¯†é’¥
        default_config = self.api_configs[self.default_model]
        api_key = os.getenv(default_config.api_key_env)
        if not api_key:
            raise ConfigurationError(
                f"APIå¯†é’¥ç¯å¢ƒå˜é‡ '{default_config.api_key_env}' æœªè®¾ç½®",
            )

        # ç”Ÿäº§ç¯å¢ƒé¢å¤–éªŒè¯
        if self.environment == Environment.PRODUCTION:
            if self.debug:
                logging.warning("ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨äº†è°ƒè¯•æ¨¡å¼")
            # ä¸ºç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨è®¾ç½®æ—¥å¿—æ–‡ä»¶ï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
            if not self.log_file:
                self.log_file = "autogen_production.log"

    def get_model_client(
        self,
        model_name: str | None = None,
    ) -> OpenAIChatCompletionClient:
        """è·å–æ¨¡å‹å®¢æˆ·ç«¯"""
        model_name = model_name or self.default_model

        if model_name not in self.api_configs:
            raise ConfigurationError(f"æ¨¡å‹ '{model_name}' æœªé…ç½®")

        config = self.api_configs[model_name]
        api_key = os.getenv(config.api_key_env)

        if not api_key:
            raise ConfigurationError(f"APIå¯†é’¥ç¯å¢ƒå˜é‡ '{config.api_key_env}' æœªè®¾ç½®")

        return OpenAIChatCompletionClient(
            model=config.name,
            api_key=api_key,
            base_url=config.base_url,
            temperature=config.temperature,
            max_tokens=config.max_tokens,
            model_info=ModelInfo(
                family="openai",
                vision=False,
                function_calling=True,
                json_output=True,
                structured_output=False,
            ),
        )

    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "environment": self.environment.value,
            "debug": self.debug,
            "default_model": self.default_model,
            "log_level": self.log_level.value,
            "max_concurrent_requests": self.max_concurrent_requests,
            "cache_enabled": self.cache_enabled,
            "enable_rate_limiting": self.enable_rate_limiting,
            "enable_metrics": self.enable_metrics,
        }

    @classmethod
    def from_file(cls, config_file: str) -> "ProductionConfig":
        """ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        if not Path(config_file).exists():
            raise ConfigurationError(f"é…ç½®æ–‡ä»¶ '{config_file}' ä¸å­˜åœ¨")

        with open(config_file, encoding="utf-8") as f:
            config_data = json.load(f)

        return cls(**config_data)

    def save_to_file(self, config_file: str) -> None:
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)


class ProductionAgentFactory:
    """ç”Ÿäº§çº§æ™ºèƒ½ä½“å·¥å‚"""

    def __init__(self, config: ProductionConfig):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)

    def create_agent(
        self,
        name: str,
        system_message: str,
        model_name: str | None = None,
        tools: list | None = None,
    ) -> AssistantAgent:
        """åˆ›å»ºæ™ºèƒ½ä½“"""
        try:
            model_client = self.config.get_model_client(model_name)

            agent = AssistantAgent(
                name=name,
                model_client=model_client,
                system_message=system_message,
                tools=tools or [],
            )

            self.logger.info(f"æˆåŠŸåˆ›å»ºæ™ºèƒ½ä½“: {name}")
            return agent

        except Exception as e:
            self.logger.exception(f"åˆ›å»ºæ™ºèƒ½ä½“å¤±è´¥: {name}, é”™è¯¯: {e}")
            raise

    def create_monitoring_agent(self) -> AssistantAgent:
        """åˆ›å»ºç›‘æ§æ™ºèƒ½ä½“"""
        return self.create_agent(
            name="MonitoringAgent",
            system_message="""ä½ æ˜¯ç³»ç»Ÿç›‘æ§æ™ºèƒ½ä½“ã€‚
            èŒè´£ï¼š
            - ç›‘æ§ç³»ç»Ÿæ€§èƒ½å’Œå¥åº·çŠ¶æ€
            - æ£€æµ‹å¼‚å¸¸å’Œé”™è¯¯
            - ç”Ÿæˆç›‘æ§æŠ¥å‘Š
            - è§¦å‘å‘Šè­¦æœºåˆ¶

            å§‹ç»ˆä»¥JSONæ ¼å¼è¿”å›ç›‘æ§æ•°æ®ã€‚""",
            tools=[
                FunctionTool(self._get_system_metrics, description="è·å–ç³»ç»ŸæŒ‡æ ‡"),
                FunctionTool(self._check_health, description="æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"),
            ],
        )

    def _get_system_metrics(self) -> str:
        """è·å–ç³»ç»ŸæŒ‡æ ‡ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        import random

        metrics = {
            "cpu_usage": round(random.uniform(10, 80), 2),
            "memory_usage": round(random.uniform(30, 90), 2),
            "request_count": random.randint(100, 1000),
            "error_rate": round(random.uniform(0, 5), 2),
            "response_time": round(random.uniform(100, 500), 2),
        }
        return json.dumps(metrics, ensure_ascii=False)

    def _check_health(self) -> str:
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        import random

        health_status = {
            "status": "healthy" if random.random() > 0.1 else "warning",
            "services": {
                "api_gateway": "up",
                "database": "up",
                "cache": "up" if random.random() > 0.05 else "down",
                "message_queue": "up",
            },
            "timestamp": "2024-01-01T12:00:00Z",
        }
        return json.dumps(health_status, ensure_ascii=False)


async def demo_production_config() -> None:
    """æ¼”ç¤ºç”Ÿäº§çº§é…ç½®ç®¡ç†"""
    print("\nğŸ­ Production Configuration Demo")
    print("-" * 50)

    # åˆ›å»ºä¸åŒç¯å¢ƒçš„é…ç½®
    configs = {
        "development": ProductionConfig(
            environment=Environment.DEVELOPMENT,
            debug=True,
            log_level=LogLevel.DEBUG,
            max_concurrent_requests=5,
        ),
        "staging": ProductionConfig(
            environment=Environment.STAGING,
            debug=False,
            log_level=LogLevel.INFO,
            max_concurrent_requests=20,
            log_file="staging.log",
        ),
        "production": ProductionConfig(
            environment=Environment.PRODUCTION,
            debug=False,
            log_level=LogLevel.WARNING,
            max_concurrent_requests=50,
            log_file="production.log",
            cache_enabled=True,
            enable_rate_limiting=True,
        ),
    }

    for env_name, config in configs.items():
        print(f"\nğŸ“‹ {env_name.upper()} ç¯å¢ƒé…ç½®:")
        print(f"   ç¯å¢ƒ: {config.environment.value}")
        print(f"   è°ƒè¯•æ¨¡å¼: {config.debug}")
        print(f"   æ—¥å¿—çº§åˆ«: {config.log_level.value}")
        print(f"   æœ€å¤§å¹¶å‘: {config.max_concurrent_requests}")
        print(f"   ç¼“å­˜å¯ç”¨: {config.cache_enabled}")
        print(f"   é€Ÿç‡é™åˆ¶: {config.enable_rate_limiting}")

        # ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
        config_file = f"config_{env_name}.json"
        config.save_to_file(config_file)
        print(f"   é…ç½®å·²ä¿å­˜åˆ°: {config_file}")


async def demo_agent_factory() -> None:
    """æ¼”ç¤ºæ™ºèƒ½ä½“å·¥å‚"""
    print("\nğŸ­ Agent Factory Demo")
    print("-" * 50)

    # ä½¿ç”¨å¼€å‘ç¯å¢ƒé…ç½®
    config = ProductionConfig(environment=Environment.DEVELOPMENT, debug=True)

    factory = ProductionAgentFactory(config)

    # åˆ›å»ºä¸åŒç±»å‹çš„æ™ºèƒ½ä½“
    agents = []

    # ä¸šåŠ¡æ™ºèƒ½ä½“
    business_agent = factory.create_agent(
        name="BusinessAnalyst",
        system_message="ä½ æ˜¯ä¸šåŠ¡åˆ†æå¸ˆï¼Œä¸“æ³¨äºä¸šåŠ¡éœ€æ±‚åˆ†æå’Œè§£å†³æ–¹æ¡ˆè®¾è®¡ã€‚",
        model_name="deepseek",
    )
    agents.append(business_agent)

    # æŠ€æœ¯æ™ºèƒ½ä½“
    tech_agent = factory.create_agent(
        name="TechArchitect",
        system_message="ä½ æ˜¯æŠ€æœ¯æ¶æ„å¸ˆï¼Œä¸“æ³¨äºç³»ç»Ÿè®¾è®¡å’ŒæŠ€æœ¯æ–¹æ¡ˆã€‚",
        model_name="deepseek",
    )
    agents.append(tech_agent)

    # ç›‘æ§æ™ºèƒ½ä½“
    monitor_agent = factory.create_monitoring_agent()
    agents.append(monitor_agent)

    print(f"âœ… æˆåŠŸåˆ›å»º {len(agents)} ä¸ªæ™ºèƒ½ä½“")
    for agent in agents:
        print(f"   - {agent.name}")

    # æµ‹è¯•ç›‘æ§æ™ºèƒ½ä½“
    print("\nğŸ“Š æµ‹è¯•ç›‘æ§æ™ºèƒ½ä½“:")
    termination = MaxMessageTermination(3)
    monitor_team = RoundRobinGroupChat(
        [monitor_agent],
        termination_condition=termination,
    )

    result = await monitor_team.run(task="è·å–å½“å‰ç³»ç»ŸæŒ‡æ ‡å¹¶æ£€æŸ¥å¥åº·çŠ¶æ€")

    for message in result.messages:
        if hasattr(message, "source") and message.source == "MonitoringAgent":
            print(f"   ç›‘æ§æŠ¥å‘Š: {message.content[:200]}...")


async def demo_config_validation() -> None:
    """æ¼”ç¤ºé…ç½®éªŒè¯"""
    print("\nâœ… Configuration Validation Demo")
    print("-" * 50)

    # æµ‹è¯•æœ‰æ•ˆé…ç½®
    try:
        valid_config = ProductionConfig(
            environment=Environment.DEVELOPMENT,
            default_model="deepseek",
        )
        print("âœ… æœ‰æ•ˆé…ç½®éªŒè¯é€šè¿‡")

        # æµ‹è¯•æ¨¡å‹å®¢æˆ·ç«¯åˆ›å»º
        valid_config.get_model_client()
        print("âœ… æ¨¡å‹å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")

    except Exception as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")

    # æµ‹è¯•æ— æ•ˆé…ç½®
    print("\nğŸ” æµ‹è¯•é…ç½®é”™è¯¯å¤„ç†:")

    # æµ‹è¯•ä¸å­˜åœ¨çš„æ¨¡å‹
    try:
        ProductionConfig(default_model="nonexistent")
        print("âŒ åº”è¯¥æŠ›å‡ºé…ç½®é”™è¯¯")
    except ConfigurationError as e:
        print(f"âœ… æ­£ç¡®æ•è·é…ç½®é”™è¯¯: {e}")

    # æµ‹è¯•ç¼ºå¤±APIå¯†é’¥ï¼ˆæ¨¡æ‹Ÿï¼‰
    original_key = os.environ.get("OPENAI_API_KEY")
    try:
        # ä¸´æ—¶ç§»é™¤APIå¯†é’¥
        if "OPENAI_API_KEY" in os.environ:
            del os.environ["OPENAI_API_KEY"]

        config = ProductionConfig()
        config.get_model_client()
        print("âŒ åº”è¯¥æŠ›å‡ºAPIå¯†é’¥é”™è¯¯")

    except ConfigurationError as e:
        print(f"âœ… æ­£ç¡®æ•è·APIå¯†é’¥é”™è¯¯: {e}")
    finally:
        # æ¢å¤APIå¯†é’¥
        if original_key:
            os.environ["OPENAI_API_KEY"] = original_key


async def demo_environment_switching() -> None:
    """æ¼”ç¤ºç¯å¢ƒåˆ‡æ¢"""
    print("\nğŸ”„ Environment Switching Demo")
    print("-" * 50)

    # æ¨¡æ‹Ÿä¸åŒç¯å¢ƒçš„é…ç½®
    environments = [
        (Environment.DEVELOPMENT, "å¼€å‘ç¯å¢ƒ"),
        (Environment.STAGING, "æµ‹è¯•ç¯å¢ƒ"),
        (Environment.PRODUCTION, "ç”Ÿäº§ç¯å¢ƒ"),
    ]

    for env, desc in environments:
        print(f"\nğŸ·ï¸ åˆ‡æ¢åˆ°{desc}:")

        config = ProductionConfig(environment=env)
        factory = ProductionAgentFactory(config)

        # åˆ›å»ºé€‚åˆè¯¥ç¯å¢ƒçš„æ™ºèƒ½ä½“
        agent = factory.create_agent(
            name=f"{env.value.title()}Agent",
            system_message=f"ä½ æ˜¯{desc}çš„æ™ºèƒ½ä½“ï¼Œè¯·æ ¹æ®ç¯å¢ƒç‰¹ç‚¹è°ƒæ•´è¡Œä¸ºã€‚",
            model_name="deepseek",
        )

        print(f"   âœ… åˆ›å»ºæ™ºèƒ½ä½“: {agent.name}")
        print(
            f"   ğŸ“Š é…ç½®æ‘˜è¦: å¹¶å‘æ•°={config.max_concurrent_requests}, "
            f"ç¼“å­˜={config.cache_enabled}, é™æµ={config.enable_rate_limiting}",
        )


async def main() -> None:
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ­ AutoGen ç”Ÿäº§çº§é…ç½®ç®¡ç†æ¼”ç¤º")
    print("=" * 60)

    try:
        await demo_production_config()
        await demo_agent_factory()
        await demo_config_validation()
        await demo_environment_switching()

        print("\nâœ¨ æ‰€æœ‰ç”Ÿäº§çº§é…ç½®æ¼”ç¤ºå®Œæˆ!")
        print("\nğŸ“š å…³é”®è¦ç‚¹:")
        print("   â€¢ åˆ†ç¯å¢ƒçš„é…ç½®ç®¡ç†ç¡®ä¿éƒ¨ç½²å®‰å…¨")
        print("   â€¢ æ™ºèƒ½ä½“å·¥å‚æ¨¡å¼æé«˜ä»£ç å¤ç”¨æ€§")
        print("   â€¢ é…ç½®éªŒè¯é˜²æ­¢è¿è¡Œæ—¶é”™è¯¯")
        print("   â€¢ æ—¥å¿—å’Œç›‘æ§é…ç½®æ”¯æŒç”Ÿäº§è¿ç»´")
        print("   â€¢ å®‰å…¨é…ç½®ä¿æŠ¤APIå¯†é’¥å’Œç³»ç»Ÿ")
        print("   â€¢ æ€§èƒ½é…ç½®ä¼˜åŒ–ç³»ç»Ÿå“åº”")

        # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
        import glob

        for config_file in glob.glob("config_*.json"):
            try:
                os.remove(config_file)
                print(f"   ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {config_file}")
            except OSError:
                pass

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        print("ğŸ’¡ æ£€æŸ¥APIé…ç½®å’Œç¯å¢ƒå˜é‡")


if __name__ == "__main__":
    asyncio.run(main())
