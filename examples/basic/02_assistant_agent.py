#!/usr/bin/env python3
"""
AutoGen å­¦ä¹ é¡¹ç›® - ç¤ºä¾‹2: åŠ©æ‰‹æ™ºèƒ½ä½“æ·±å…¥æ¢ç´¢

å±•ç¤ºAssistantAgentçš„å„ç§é…ç½®é€‰é¡¹å’ŒåŠŸèƒ½ç‰¹æ€§ã€‚

å­¦ä¹ è¦ç‚¹:
- AssistantAgentçš„è¯¦ç»†é…ç½®
- ç³»ç»Ÿæ¶ˆæ¯çš„é‡è¦æ€§
- ä¸åŒçš„æ¨¡å‹å‚æ•°è®¾ç½®
- æ¶ˆæ¯å†å²ç®¡ç†
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
"""

import asyncio
import os

from autogen_agentchat.agents import AssistantAgent
from autogen_core.models import ModelInfo
from autogen_ext.models.openai import OpenAIChatCompletionClient
from dotenv import load_dotenv

load_dotenv()


class AgentDemo:
    """Demonstration class for AssistantAgent capabilities"""

    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")

    def create_model_client(
        self,
        temperature: float = 0.7,
        max_tokens: int = 1000,
    ) -> OpenAIChatCompletionClient:
        """Create a configured DeepSeek-compatible model client"""
        return OpenAIChatCompletionClient(
            model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
            api_key=self.api_key,
            base_url=os.getenv("OPENAI_API_BASE", "https://api.deepseek.com/v1"),
            # Model parameters for controlling behavior
            temperature=temperature,  # Creativity level (0.0-1.0)
            max_tokens=max_tokens,  # Maximum response length
            top_p=0.9,  # Nucleus sampling parameter
            model_info=ModelInfo(
                family="openai",
                vision=False,
                function_calling=True,
                json_output=True,
                structured_output=False,
            ),
        )

    async def demo_basic_assistant(self) -> None:
        """Demonstrate basic assistant creation and usage"""
        print("\nğŸ”§ Basic Assistant Agent Demo")
        print("-" * 40)

        model_client = self.create_model_client(temperature=0.3)

        # Create a specialized assistant
        coding_assistant = AssistantAgent(
            name="CodingMentor",
            model_client=model_client,
            system_message="""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Pythonç¼–ç¨‹å¯¼å¸ˆã€‚
            ä½ çš„èŒè´£æ˜¯:
            1. æ¸…æ™°åœ°è§£é‡Šç¼–ç¨‹æ¦‚å¿µ
            2. æä¾›å¸¦æ³¨é‡Šçš„ä»£ç ç¤ºä¾‹
            3. å»ºè®®æœ€ä½³å®è·µ
            4. å¸®åŠ©è°ƒè¯•é—®é¢˜

            æ€»æ˜¯ç”¨markdownæ ¼å¼åŒ–ä»£ç ï¼Œå¹¶è§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹ã€‚""",
        )

        # Ask a coding question
        task = "è§£é‡ŠPythonä¸­åˆ—è¡¨æ¨å¯¼å¼å’Œç”Ÿæˆå™¨è¡¨è¾¾å¼çš„åŒºåˆ«ï¼Œå¹¶æä¾›ç¤ºä¾‹ã€‚"
        result = await coding_assistant.run(task=task)

        print(f"ğŸ¤– {coding_assistant.name} è¯´:")
        print(f"   {result.messages[-1].content[:200]}...")
        print(f"   [å›å¤é•¿åº¦: {len(result.messages[-1].content)} å­—ç¬¦]")

    async def demo_creative_assistant(self) -> None:
        """Demonstrate creative assistant with higher temperature"""
        print("\nğŸ¨ Creative Assistant Demo")
        print("-" * 40)

        # Higher temperature for more creative responses
        model_client = self.create_model_client(temperature=0.9)

        creative_writer = AssistantAgent(
            name="CreativeWriter",
            model_client=model_client,
            system_message="""ä½ æ˜¯ä¸€ä½å¯Œæœ‰åˆ›æ„çš„å†™ä½œåŠ©æ‰‹ã€‚
            ä½ æ“…é•¿:
            - åˆ›ä½œå¼•äººå…¥èƒœçš„æ•…äº‹
            - åˆ›é€ ç”ŸåŠ¨çš„æè¿°
            - å¼€å‘ç‹¬ç‰¹çš„è§’è‰²
            - ä»¥å„ç§é£æ ¼å’Œç±»å‹å†™ä½œ

            åœ¨å›å¤ä¸­è¦å¯Œæœ‰æƒ³è±¡åŠ›å’Œè¡¨ç°åŠ›ã€‚""",
        )

        task = "å†™ä¸€ä¸ªå…³äºAIå‘ç°è‡ªå·±èƒ½å¤Ÿåšæ¢¦çš„ç§‘å¹»æ•…äº‹å¼€å¤´ã€‚"
        result = await creative_writer.run(task=task)

        print(f"âœ¨ {creative_writer.name} åˆ›ä½œ:")
        print(f"   {result.messages[-1].content[:300]}...")

    async def demo_conversation_memory(self) -> None:
        """Demonstrate conversation memory and context"""
        print("\nğŸ§  Conversation Memory Demo")
        print("-" * 40)

        model_client = self.create_model_client(temperature=0.5)

        memory_assistant = AssistantAgent(
            name="MemoryKeeper",
            model_client=model_client,
            system_message="""ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰å‡ºè‰²è®°å¿†åŠ›çš„åŠ©æ‰‹ã€‚
            ä½ èƒ½è®°ä½æ‰€æœ‰ä¹‹å‰çš„å¯¹è¯ï¼Œå¹¶å¯ä»¥å¼•ç”¨å®ƒä»¬ã€‚
            æ€»æ˜¯ç¡®è®¤ä½ ä»ä¹‹å‰çš„äº’åŠ¨ä¸­è®°ä½äº†ä»€ä¹ˆã€‚""",
        )

        # First interaction
        print("ğŸ’¬ ç¬¬ä¸€æ¬¡å¯¹è¯:")
        result1 = await memory_assistant.run(task="æˆ‘çš„åå­—æ˜¯Aliceï¼Œæˆ‘å–œæ¬¢Pythonç¼–ç¨‹ã€‚")
        print(f"   åŠ©æ‰‹: {result1.messages[-1].content}")

        # Second interaction - testing memory
        print("\nğŸ’¬ ç¬¬äºŒæ¬¡å¯¹è¯ (æµ‹è¯•è®°å¿†):")
        result2 = await memory_assistant.run(task="æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘å–œæ¬¢ä»€ä¹ˆï¼Ÿ")
        print(f"   åŠ©æ‰‹: {result2.messages[-1].content}")

        # Show conversation history
        print(f"\nğŸ“Š å¯¹è¯ä¸­æ€»æ¶ˆæ¯æ•°: {len(result2.messages)}")

    async def demo_error_handling(self) -> None:
        """Demonstrate error handling with invalid requests"""
        print("\nâš ï¸  Error Handling Demo")
        print("-" * 40)

        model_client = self.create_model_client()

        assistant = AssistantAgent(
            name="RobustAssistant",
            model_client=model_client,
            system_message="ä½ æ˜¯ä¸€ä¸ªä¼˜é›…å¤„ç†é”™è¯¯çš„åŠ©æ‰‹ã€‚",
        )

        try:
            # This should work fine
            result = await assistant.run(task="2 + 2 ç­‰äºå¤šå°‘ï¼Ÿ")
            print(f"âœ… æ­£å¸¸è¯·æ±‚: {result.messages[-1].content}")

            # Test with very long input (might hit token limits)
            long_task = "è§£é‡Šè¿™ä¸ª: " + "éå¸¸ " * 1000 + "å…³äºAutoGençš„é•¿é—®é¢˜"
            result = await assistant.run(task=long_task)
            print(f"âœ… é•¿è¯·æ±‚å¤„ç†: å›å¤é•¿åº¦ {len(result.messages[-1].content)}")

        except Exception as e:
            print(f"âŒ æ•è·é”™è¯¯: {e}")
            print("ğŸ’¡ è¿™å±•ç¤ºäº†åœ¨ç”Ÿäº§ä»£ç ä¸­é”™è¯¯å¤„ç†çš„é‡è¦æ€§")


async def main() -> None:
    """Main demonstration function"""
    print("ğŸ¤– AutoGen AssistantAgent æ·±å…¥æ¢ç´¢")
    print("=" * 50)

    try:
        demo = AgentDemo()

        # Run all demonstrations
        await demo.demo_basic_assistant()
        await demo.demo_creative_assistant()
        await demo.demo_conversation_memory()
        await demo.demo_error_handling()

        print("\nâœ¨ æ‰€æœ‰æ¼”ç¤ºæˆåŠŸå®Œæˆ!")
        print("\nğŸ“š å…³é”®è¦ç‚¹:")
        print("   â€¢ AssistantAgent é«˜åº¦å¯é…ç½®")
        print("   â€¢ ç³»ç»Ÿæ¶ˆæ¯å®šä¹‰æ™ºèƒ½ä½“è¡Œä¸º")
        print("   â€¢ Temperature æ§åˆ¶åˆ›é€ æ€§ä¸ä¸€è‡´æ€§")
        print("   â€¢ æ™ºèƒ½ä½“ç»´æŠ¤å¯¹è¯è®°å¿†")
        print("   â€¢ é€‚å½“çš„é”™è¯¯å¤„ç†è‡³å…³é‡è¦")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        print("ğŸ’¡ ç¡®ä¿ä½ çš„APIå¯†é’¥è®¾ç½®æ­£ç¡®ä¸”æœ‰æ•ˆ")


if __name__ == "__main__":
    asyncio.run(main())
